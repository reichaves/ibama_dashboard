import os
import json
from typing import Dict, Any, Optional, Literal
from openai import OpenAI
import google.generativeai as genai
from decouple import config
import pandas as pd

# Importa a ferramenta de busca que usa a API da Serper
from src.utils.tools import search_internet

class LLMIntegration:
    # ... (todo o in√≠cio da classe permanece o mesmo) ...
    def __init__(self, database=None):
        self.database = database
        self.groq_client = None
        self.gemini_model = None
        self.groq_model_name = "llama-3.3-70b-versatile"
        self.gemini_model_name = "gemini-1.5-pro"

        groq_api_key = config('GROQ_API_KEY')
        if groq_api_key:
            self.groq_client = OpenAI(api_key=groq_api_key, base_url="https://api.groq.com/openai/v1")

        google_api_key = config('GOOGLE_API_KEY')
        if google_api_key:
            genai.configure(api_key=google_api_key)
            self.gemini_model = genai.GenerativeModel(model_name=self.gemini_model_name)

    def _get_system_prompt(self) -> str:
        try:
            schema_df = self.database.get_table_info()
            schema_str = "\n".join([f"- {row['name']} ({row['type']})" for _, row in schema_df.iterrows()])
        except Exception:
            schema_str = "N√£o foi poss√≠vel carregar o esquema da tabela."
        return f"""
        Voc√™ √© um assistente especialista em an√°lise de dados ambientais do IBAMA.
        Sua fun√ß√£o √© usar os dados fornecidos para formular uma resposta clara e completa.
        Esquema da tabela `ibama_infracao`:
        {schema_str}
        """

    def _decide_tool(self, question: str) -> Literal['database', 'internet']:
        question_lower = question.lower()
        
        web_keywords = [
            "endere√ßo", "o que √©", "significado de", "site oficial", "telefone", 
            "contato", "hist√≥ria", "quem √© o presidente", "localiza√ß√£o", "site"
        ]
        if any(keyword in question_lower for keyword in web_keywords):
            return 'internet'

        db_keywords = ["mostre", "liste", "quais s√£o", "infra√ß√µes", "multas", "autos de infra√ß√£o", "relat√≥rio"]
        if "cnpj" in question_lower and not any(keyword in question_lower for keyword in db_keywords):
            return 'internet'

        return 'database'

    def _generate_final_answer_from_text(self, context: str, question: str, provider: str) -> str:
        prompt = f"Com base no seguinte contexto, responda √† pergunta do usu√°rio de forma clara e concisa.\n\nContexto:\n{context}\n\nPergunta do Usu√°rio:\n{question}"
        
        if provider == 'gemini' and self.gemini_model:
            response = self.gemini_model.generate_content(prompt, generation_config={"temperature": 0.2})
            return response.text
        elif provider == 'groq' and self.groq_client:
            response = self.groq_client.chat.completions.create(
                model=self.groq_model_name,
                messages=[{"role": "system", "content": self._get_system_prompt()}, {"role": "user", "content": prompt}],
                temperature=0.2
            )
            return response.choices[0].message.content
        return "Provedor de LLM n√£o configurado."

    def query(self, question: str, provider: Literal['groq', 'gemini']) -> Dict[str, Any]:
        if (provider == 'groq' and not self.groq_client) or (provider == 'gemini' and not self.gemini_model):
            return {"answer": f"Provedor '{provider}' n√£o configurado. Verifique suas chaves de API.", "source": "error"}

        tool_choice = self._decide_tool(question)
        print(f"ü§ñ Ferramenta escolhida: {tool_choice}")

        try:
            if tool_choice == 'internet':
                search_results = search_internet(question)
                final_answer = self._generate_final_answer_from_text(search_results, question, provider)
                return {"answer": final_answer, "source": "internet", "debug_info": {"search_query": question, "results": search_results}}
            
            elif tool_choice == 'database':
                sql_query = self.generate_sql(question, provider)
                if not sql_query:
                    return {"answer": "N√£o consegui gerar uma consulta SQL. Tente reformular.", "source": "error"}
                
                db_results = self.database.execute_query(sql_query)
                
                if db_results.empty:
                    print("‚ö†Ô∏è Consulta inicial n√£o retornou resultados. Tentando uma consulta de fallback mais ampla...")
                    
                    main_keyword = None
                    if 'fauna' in question.lower(): main_keyword = 'fauna'
                    elif 'flora' in question.lower(): main_keyword = 'flora'
                    elif 'pesca' in question.lower(): main_keyword = 'pesca'
                    
                    if main_keyword:
                        fallback_sql = f"SELECT NOME_INFRATOR, CPF_CNPJ_INFRATOR, TIPO_INFRACAO, DES_INFRACAO FROM ibama_infracao WHERE LOWER(TIPO_INFRACAO) = '{main_keyword}' LIMIT 5"
                        print(f"üîß Executando consulta de fallback: {fallback_sql}")
                        db_results = self.database.execute_query(fallback_sql)
                        
                        if not db_results.empty:
                            fallback_message = "A sua consulta original foi muito espec√≠fica e n√£o retornou resultados. Aqui est√£o alguns registros mais gerais sobre o tema:\n\n"
                            final_answer = fallback_message + self._format_results(question, db_results)
                        else:
                            final_answer = f"N√£o encontrei dados para '{main_keyword}', mesmo em uma busca mais ampla."
                    else:
                        final_answer = "N√£o encontrei dados para sua consulta no banco de dados."
                else:
                    final_answer = self._format_results(question, db_results)
                
                return {"answer": final_answer, "source": "database", "debug_info": {"sql_query": sql_query}}

        except Exception as e:
            print(f"‚ùå Erro ao processar a query: {e}")
            return {"answer": f"Ocorreu um erro inesperado: {str(e)}", "source": "error"}

    def generate_sql(self, question: str, provider: str) -> Optional[str]:
        print("Gerando SQL com LLM...")
        
        prompt = f"""
        Gere uma √∫nica consulta SQL para DuckDB para responder √† seguinte pergunta.
        Retorne APENAS o c√≥digo SQL, nada mais.

        {self._get_system_prompt()}

        Pergunta: {question}

        Regras IMPORTANT√çSSIMAS e OBRIGAT√ìRIAS:
        1. Para an√°lises temporais, use `EXTRACT(YEAR FROM TRY_CAST(DAT_HORA_AUTO_INFRACAO AS TIMESTAMP)) AS ano`.
        2. Para fazer qualquer c√°lculo (SUM, AVG, etc.) na coluna `VAL_AUTO_INFRACAO`, voc√™ DEVE seguir estes dois passos na ordem:
           a. Primeiro, filtre os valores inv√°lidos: `WHERE VAL_AUTO_INFRACAO IS NOT NULL AND VAL_AUTO_INFRACAO != ''`
           b. Segundo, use a express√£o EXATA para converter o valor: `CAST(REPLACE(VAL_AUTO_INFRACAO, ',', '.') AS DOUBLE)`
        3. Sempre inclua `CPF_CNPJ_INFRATOR` junto com `NOME_INFRATOR` no SELECT.
        4. Ao usar fun√ß√µes de agrega√ß√£o como SUM, AVG, COUNT, SEMPRE d√™ um apelido (alias) para a coluna.
        5. INTERPRETA√á√ÉO DE INTEN√á√ÉO: Se o usu√°rio pedir para "mostrar" algo "com [uma coluna]" (ex: 'infra√ß√µes de fauna com CNPJ'), isso √© um pedido para INCLUIR a coluna no `SELECT`. N√ÉO adicione um filtro `WHERE` para essa coluna a menos que o usu√°rio pe√ßa explicitamente.
        """
        
        if provider == 'gemini' and self.gemini_model:
            response = self.gemini_model.generate_content(prompt, generation_config={"temperature": 0.0})
            sql = response.text
        elif provider == 'groq' and self.groq_client:
            response = self.groq_client.chat.completions.create(
                model=self.groq_model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0, max_tokens=500
            )
            sql = response.choices[0].message.content
        else:
            return None

        sql = sql.strip().replace('```sql', '').replace('```', '').strip()
        return sql if sql.lower().startswith(('select', 'with')) else None

    def _fix_encoding(self, text: str) -> str:
        """Corrige problemas comuns de codifica√ß√£o de caracteres."""
        if not isinstance(text, str):
            return text
        # Mapeamento dos erros de encoding mais comuns
        replacements = {
            '√É¬ß': '√ß', '√É‚Ä°': '√á',
            '√É¬£': '√£', '√É¬µ': '√µ',
            '√É¬°': '√°', '√É¬©': '√©', '√É¬≠': '√≠', '√É¬≥': '√≥', '√É¬∫': '√∫',
            '√É¬¢': '√¢', '√É¬™': '√™', '√É¬¥': '√¥',
            '√É ': '√†',
            '√Ç¬∫': '¬∫', '√Ç¬™': '¬™'
        }
        for bad, good in replacements.items():
            text = text.replace(bad, good)
        return text

    def _format_results(self, question: str, results: pd.DataFrame) -> str:
        """Formata os resultados de uma consulta SQL em uma resposta de texto amig√°vel."""
        # --- ALTERA√á√ÉO AQUI: Aplica a corre√ß√£o de encoding em todas as colunas de texto ---
        for col in results.select_dtypes(include=['object']).columns:
            results[col] = results[col].apply(self._fix_encoding)

        if len(results) == 1 and len(results.columns) == 1:
            value = results.iloc[0, 0]
            if isinstance(value, (int, float)):
                if "valor" in question.lower():
                    return f"O resultado da sua consulta √©: **R$ {value:,.2f}**."
                else:
                    return f"O total encontrado √©: **{int(value):,}**."
            else:
                return f"O resultado encontrado √©: **{value}**"

        results.columns = [self._fix_encoding(col.replace('_', ' ').title()) for col in results.columns]
        return results.to_markdown(index=False)