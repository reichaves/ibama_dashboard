import pandas as pd
import streamlit as st
from typing import List, Dict, Any, Optional
import hashlib
import time
import random
import uuid

class SupabasePaginator:
    """Classe CORRIGIDA DEFINITIVAMENTE para buscar dados √∫nicos do Supabase."""
    
    def __init__(self, supabase_client):
        self.supabase = supabase_client
        self.page_size = 1000  
        self.max_pages = 25    # Suficiente para 25k registros
    
    def _get_session_key(self, table_name: str = 'ibama_infracao', filters: str = "") -> str:
        """Gera chave √∫nica POR SESS√ÉO para cache isolado."""
        if 'session_uuid' not in st.session_state:
            st.session_state.session_uuid = str(uuid.uuid4())[:8]
        
        session_id = st.session_state.session_uuid
        filter_hash = hashlib.md5(f"{table_name}_{filters}_{session_id}".encode()).hexdigest()[:8]
        return f"data_{session_id}_{filter_hash}"
    
    def get_real_count_corrected(self, table_name: str = 'ibama_infracao') -> Dict[str, Any]:
        """
        VERS√ÉO CORRIGIDA DEFINITIVA: Conta registros √∫nicos corretamente.
        Baseada na verifica√ß√£o que mostrou 21.019 √∫nicos reais.
        """
        try:
            print("üîç CONTAGEM REAL CORRIGIDA: Iniciando contagem definitiva...")
            
            # 1. Conta total de registros
            result_total = self.supabase.table(table_name).select('*', count='exact').limit(1).execute()
            total_records = getattr(result_total, 'count', 0)
            print(f"üìä Total de registros no banco: {total_records:,}")
            
            # 2. Busca TODOS os NUM_AUTO_INFRACAO de forma eficiente
            print("üîÑ Buscando todos os NUM_AUTO_INFRACAO...")
            
            all_num_auto = []
            page = 0
            
            while True:
                start = page * self.page_size
                end = start + self.page_size - 1
                
                try:
                    # Busca apenas NUM_AUTO_INFRACAO para efici√™ncia
                    result = self.supabase.table(table_name).select('NUM_AUTO_INFRACAO').range(start, end).execute()
                    
                    if not result.data or len(result.data) == 0:
                        break
                    
                    # Adiciona todos os valores (incluindo poss√≠veis duplicatas)
                    for record in result.data:
                        num_auto = record.get('NUM_AUTO_INFRACAO')
                        if num_auto and str(num_auto).strip():  # S√≥ aceita valores v√°lidos
                            all_num_auto.append(num_auto)
                    
                    print(f"   üìÑ P√°gina {page + 1}: {len(result.data)} registros coletados")
                    
                    if len(result.data) < self.page_size:
                        break
                    
                    page += 1
                    
                    if page >= self.max_pages:
                        print(f"   ‚ö†Ô∏è Limite de p√°ginas atingido: {self.max_pages}")
                        break
                        
                except Exception as e:
                    print(f"   ‚ùå Erro na p√°gina {page + 1}: {e}")
                    break
            
            # 3. An√°lise correta dos dados coletados
            total_coletados = len(all_num_auto)
            
            # Conta √∫nicos usando pandas (mais confi√°vel)
            df_temp = pd.DataFrame({'NUM_AUTO_INFRACAO': all_num_auto})
            unique_count = df_temp['NUM_AUTO_INFRACAO'].nunique()
            
            # Identifica duplicatas reais
            duplicates_count = df_temp['NUM_AUTO_INFRACAO'].value_counts()
            real_duplicates = duplicates_count[duplicates_count > 1]
            duplicated_infractions = len(real_duplicates)
            
            print(f"‚úÖ AN√ÅLISE CORRIGIDA CONCLU√çDA:")
            print(f"   üìä Total coletado: {total_coletados:,}")
            print(f"   üî¢ √önicos (pandas): {unique_count:,}")
            print(f"   üîÑ NUM_AUTO duplicados: {duplicated_infractions:,}")
            print(f"   üìâ Total de registros duplicados: {total_coletados - unique_count:,}")
            
            # Verifica se bate com expectativa (21.019 √∫nicos)
            expected_unique = 21019
            if unique_count == expected_unique:
                print(f"üéâ SUCESSO: Contagem bate com dados originais ({expected_unique:,} √∫nicos)")
            else:
                print(f"‚ö†Ô∏è DIFEREN√áA: Esperado {expected_unique:,}, obtido {unique_count:,}")
            
            return {
                'total_records': total_records,
                'unique_infractions': unique_count,
                'duplicates': total_records - unique_count,
                'duplicated_infractions': duplicated_infractions,
                'real_duplicates_examples': dict(real_duplicates.head(10)) if not real_duplicates.empty else {},
                'timestamp': pd.Timestamp.now(),
                'method': 'pandas_corrected',
                'total_collected': total_coletados
            }
            
        except Exception as e:
            print(f"‚ùå Erro na contagem real corrigida: {e}")
            return {
                'total_records': 0,
                'unique_infractions': 0,
                'duplicates': 0,
                'timestamp': pd.Timestamp.now(),
                'error': str(e)
            }
    
    def get_all_records_corrected(self, table_name: str = 'ibama_infracao', cache_key: str = None) -> pd.DataFrame:
        """
        VERS√ÉO CORRIGIDA DEFINITIVA: Busca TODOS os registros √∫nicos corretamente.
        """
        if cache_key is None:
            cache_key = self._get_session_key(table_name)
        
        cache_storage_key = f"paginated_data_{cache_key}"
        if cache_storage_key in st.session_state:
            print(f"‚úÖ Retornando dados √∫nicos do cache da sess√£o")
            return st.session_state[cache_storage_key]
        
        print(f"üîÑ BUSCA CORRIGIDA: Carregando TODOS os dados √∫nicos...")
        
        all_data = []
        page = 0
        
        while True:
            start = page * self.page_size
            end = start + self.page_size - 1
            
            print(f"   üìÑ P√°gina {page + 1}: registros {start} a {end}")
            
            try:
                # Busca todos os campos
                result = self.supabase.table(table_name).select('*').range(start, end).execute()
                
                if not result.data or len(result.data) == 0:
                    print(f"   ‚úÖ Fim da pagina√ß√£o na p√°gina {page + 1}")
                    break
                
                # Adiciona todos os registros (incluindo poss√≠veis duplicatas)
                # A deduplica√ß√£o ser√° feita no final usando pandas
                all_data.extend(result.data)
                
                print(f"   üìä Carregados: {len(result.data)} registros (total: {len(all_data):,})")
                
                if len(result.data) < self.page_size:
                    print(f"   ‚úÖ √öltima p√°gina alcan√ßada")
                    break
                
                page += 1
                
                if page >= self.max_pages:
                    print(f"   ‚ö†Ô∏è Limite de p√°ginas atingido: {self.max_pages}")
                    break
                
            except Exception as e:
                print(f"   ‚ùå Erro na p√°gina {page + 1}: {e}")
                break
        
        print(f"üéâ DADOS CARREGADOS: {len(all_data):,} registros")
        
        # Converte para DataFrame
        df = pd.DataFrame(all_data)
        
        # DEDUPLICA√á√ÉO CORRETA usando pandas
        if not df.empty and 'NUM_AUTO_INFRACAO' in df.columns:
            original_count = len(df)
            
            # Remove registros com NUM_AUTO_INFRACAO inv√°lido
            df_valid = df[df['NUM_AUTO_INFRACAO'].notna() & (df['NUM_AUTO_INFRACAO'] != '')].copy()
            
            # Remove duplicatas mantendo o primeiro registro
            df_unique = df_valid.drop_duplicates(subset=['NUM_AUTO_INFRACAO'], keep='first')
            
            final_count = len(df_unique)
            duplicates_removed = original_count - final_count
            
            print(f"‚úÖ DEDUPLICA√á√ÉO CONCLU√çDA:")
            print(f"   üìä Registros originais: {original_count:,}")
            print(f"   üî¢ Registros √∫nicos: {final_count:,}")
            print(f"   üìâ Duplicatas removidas: {duplicates_removed:,}")
            
            # Verifica se chegou pr√≥ximo da expectativa
            expected_unique = 21019
            if final_count >= expected_unique * 0.98:  # 98% ou mais
                print(f"üéâ SUCESSO: Carregados {final_count:,} registros √∫nicos (‚â•98% do esperado)")
            elif final_count >= expected_unique * 0.90:  # 90% ou mais
                print(f"‚ö†Ô∏è PARCIAL: Carregados {final_count:,} registros √∫nicos (‚â•90% do esperado)")
            else:
                print(f"‚ùå INSUFICIENTE: Carregados apenas {final_count:,} registros √∫nicos (<90% do esperado)")
            
            df = df_unique
        
        # Armazena no cache da sess√£o
        st.session_state[cache_storage_key] = df
        print(f"üíæ Dados √∫nicos armazenados no cache da sess√£o")
        
        return df
    
    # M√©todos mantidos para compatibilidade - agora chamam as vers√µes corrigidas
    def get_real_count(self, table_name: str = 'ibama_infracao') -> Dict[str, Any]:
        """M√©todo original - chama a vers√£o corrigida."""
        return self.get_real_count_corrected(table_name)
    
    def get_all_records(self, table_name: str = 'ibama_infracao', cache_key: str = None) -> pd.DataFrame:
        """M√©todo original - chama a vers√£o corrigida."""
        return self.get_all_records_corrected(table_name, cache_key)
    
    def get_filtered_data(self, selected_ufs: List[str] = None, year_range: tuple = None) -> pd.DataFrame:
        """Busca dados filtrados com garantia de unicidade."""
        filter_str = f"ufs_{selected_ufs}_years_{year_range}"
        cache_key = self._get_session_key('ibama_infracao', filter_str)
        
        print(f"üîç Buscando dados filtrados √∫nicos...")
        
        # Busca todos os dados √∫nicos desta sess√£o
        df = self.get_all_records_corrected('ibama_infracao', cache_key)
        
        if df.empty:
            return df
        
        original_count = len(df)
        print(f"üìä Dataset base: {original_count:,} registros √∫nicos")
        
        # Aplica filtros
        if selected_ufs and 'UF' in df.columns:
            df = df[df['UF'].isin(selected_ufs)]
            print(f"   üó∫Ô∏è Ap√≥s filtro UF: {len(df):,} registros")
        
        if year_range and 'DAT_HORA_AUTO_INFRACAO' in df.columns:
            try:
                df['DAT_HORA_AUTO_INFRACAO'] = pd.to_datetime(df['DAT_HORA_AUTO_INFRACAO'], errors='coerce')
                df = df[
                    (df['DAT_HORA_AUTO_INFRACAO'].dt.year >= year_range[0]) &
                    (df['DAT_HORA_AUTO_INFRACAO'].dt.year <= year_range[1])
                ]
                print(f"   üìÖ Ap√≥s filtro ano {year_range}: {len(df):,} registros")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erro no filtro de data: {e}")
        
        print(f"‚úÖ Dados filtrados finais: {len(df):,} registros √∫nicos")
        return df
    
    def clear_cache(self):
        """Limpa o cache espec√≠fico desta sess√£o."""
        try:
            session_uuid = st.session_state.get('session_uuid', '')
            
            keys_to_remove = []
            for key in st.session_state.keys():
                if key.startswith(f'paginated_data_data_{session_uuid}'):
                    keys_to_remove.append(key)
            
            for key in keys_to_remove:
                del st.session_state[key]
            
            st.session_state.session_uuid = str(uuid.uuid4())[:8]
            
            print(f"üßπ Cache da sess√£o limpo ({len(keys_to_remove)} chaves removidas)")
            return True
        except Exception as e:
            print(f"‚ùå Erro ao limpar cache: {e}")
            return False
    
    def get_sample_data(self, limit: int = 1000) -> pd.DataFrame:
        """Busca uma amostra dos dados para testes."""
        try:
            print(f"üîç Buscando amostra de {limit} registros...")
            
            result = self.supabase.table('ibama_infracao').select('*').limit(limit).execute()
            
            if result.data:
                df = pd.DataFrame(result.data)
                
                # Remove duplicatas da amostra usando pandas
                if 'NUM_AUTO_INFRACAO' in df.columns:
                    original_count = len(df)
                    df = df.drop_duplicates(subset=['NUM_AUTO_INFRACAO'], keep='first')
                    unique_count = len(df)
                    
                    print(f"üìä Amostra: {original_count} registros ‚Üí {unique_count} √∫nicos")
                
                return df
            else:
                return pd.DataFrame()
                
        except Exception as e:
            print(f"‚ùå Erro ao buscar amostra: {e}")
            return pd.DataFrame()
    
    def validate_data_integrity(self) -> Dict[str, Any]:
        """Valida a integridade dos dados usando m√©todo corrigido."""
        try:
            print("üîç Validando integridade com m√©todo corrigido...")
            
            # Usa a fun√ß√£o corrigida de contagem
            real_counts = self.get_real_count_corrected()
            
            if 'error' in real_counts:
                return {"error": "Erro na valida√ß√£o"}
            
            validation_info = {
                "total_records": real_counts['total_records'],
                "unique_infractions": real_counts['unique_infractions'],
                "duplicates": real_counts['duplicates'],
                "expected_unique": 21019,
                "accuracy": (real_counts['unique_infractions'] / 21019) * 100 if real_counts['unique_infractions'] > 0 else 0,
                "status": "‚úÖ CORRETO" if real_counts['unique_infractions'] >= 21000 else "‚ùå INCORRETO",
                "method": "pandas_corrected"
            }
            
            return validation_info
            
        except Exception as e:
            return {"error": f"Erro na valida√ß√£o: {str(e)}"}
    
    # FUN√á√ÉO ADICIONAL PARA DEBUG
    def debug_duplicates_comparison(self) -> Dict[str, Any]:
        """Compara resultado com dados originais para debug."""
        try:
            print("üêõ DEBUG: Comparando com dados originais esperados...")
            
            result = self.get_real_count_corrected()
            
            debug_info = {
                "app_results": {
                    "total": result.get('total_records', 0),
                    "unique": result.get('unique_infractions', 0),
                    "duplicates": result.get('duplicates', 0)
                },
                "expected_results": {
                    "total": 21030,
                    "unique": 21019,
                    "duplicates": 11
                },
                "differences": {
                    "total_diff": result.get('total_records', 0) - 21030,
                    "unique_diff": result.get('unique_infractions', 0) - 21019,
                    "duplicates_diff": result.get('duplicates', 0) - 11
                }
            }
            
            # Avalia√ß√£o
            if abs(debug_info["differences"]["unique_diff"]) <= 10:
                debug_info["status"] = "‚úÖ CORRETO"
            else:
                debug_info["status"] = "‚ùå INCORRETO"
            
            print(f"DEBUG RESULT: {debug_info['status']}")
            
            return debug_info
            
        except Exception as e:
            return {"error": f"Erro no debug: {str(e)}"}
